Metadata-Version: 2.1
Name: bel-digital-handwriting-py
Version: 0.0.4
Summary: Пакет для аналіза беларускіх тэкстаў і вызначэння лічбавага почырку пісьменніка
Home-page: https://github.com/Kononenko-Daniil/bel-digital-handwriting-py
Author: Daniil Kononenko
License: MIT
Project-URL: Source, https://github.com/Kononenko-Daniil/bel-digital-handwriting-py
Description-Content-Type: text/markdown
License-File: LICENSE

# bel-digital-handwriting-py
**bel-digital-handwriting-py** - гэта Python бібліятэка, з дапамогай якой вы можаце хутка
аналізаваць беларускія тэксты па спецыяльных крытэрыях. 

```python
import BelDigitalHandwriting.BelDHAnalyser as BelDHAnalyser

text_file = open("text.txt", "r", encoding="utf-8")
text = text_file.read()

analyze = BelDHAnalyser.analyse_text(text)
```

## Што можа гэта бібліятэка
 - **Аналізаваць** тэксты:
    ```
    analyze = BelDHAnalyser.analyse_text(text)
    ```
 - **Сумяшчаць** аналізы тэкстаў
    ```
    commom_analyze = analyze_1 + analyze_2
    ```

## Як карыстацца гэтай бібліятэкай
Каб пачаць выкарыстоўваць **bel-digital-handwriting-py**, вы павінны ўсталяваць бібліятэку
праз PIP:

```commandline
pip install bel-digital-handwriting-py
```

## Як працуе гэты пакет
У гэтым раздзеле будуць апісаны асноўныя прынцыпы работы **bel-digital-handwriting-py**

### Крытыэрыі аналізу
Для выяўлення лічбавага почырку пісьменніка быў складзены спіс крытыэрыяў, па якім будзе праходзіць
аналіз тэксту:
 - Частата з'яўлення ў тэксце **кожнага** сімвала:
 
 $$ \nu_{сімвала} = {колькасць\ паўтарэнняў\ сімвала \over колькасць\ сімвалаў}$$
 
 - Частата з'яўлення ў тэксце **галосных** і **зычных** літар: 
 
 $$ \nu_{галосных} = {колькасць\ галосных \over колькасць\ літар}\qquad \nu_{зычных} = {колькасць\ зычных \over колькасць\ літар}$$
 
 - Сярэдняя даўжыня **слова**: 
 
 $$ \langle l_{слова} \rangle = {сума\ даўжынь\ усіх\ слоў \over колькасць\ слоў}$$
 
 - Сярэдняя даўжыня сказа (па колькасьці **сімвалаў** і колькасьці **слоў**): 
 
 $$ \langle l_{сказа:\ сімвалы} \rangle = {колькасць\ усіх\ сімвалаў \over колькасць\ сказаў} \qquad \langle l_{сказа:\ словы} \rangle = {колькасць\ усіх\ слоў \over колькасць\ сказаў}$$
 
 - Сярэдняя колькасць косак **(,;)** на сказ: 
 
 $$ \langle N_{косак} \rangle = {колькасць\ усіх\ косак \over колькасць\ сказаў}$$
 
 - Працэнт **клічных** і **пытальных** сказаў: 
 
 $$ \nu_{кліч} = {колькасць\ клічнікаў \over колькасць\ сказаў}\qquad \nu_{пыт} = {колькасць\ пытальнікаў \over колькасць\ сказаў}$$
 
 - Частата выкарыстання слоў кожнай часціны мовы (больш падрабязна пра гэта напісана ў [наступным раздзеле](#выкарыстанне-граматычнай-базы)): 
 
 $$ \nu_x = {колькасць\ слоў\ гэтай\ часціны\ мовы \over колькасць\ слоў}$$

 - Статыстыка па парам слоў, якія пачынаюцца/заканчваюцца на галосны/зычны **(ГГ, ГЗ, ЗГ, ЗЗ)**:

 $$ \nu_{тыпа\ пар} = {колькасць\ пар\ аднаго\ тыпа \over колькасць\ ўсіх\ пар}$$

### Выкарыстанне Граматычнай базы
Для вызначэння часціны мовы, да якой адносіцца канкрэтнае слова была выкарыстана [Граматычная база](https://bnkorpus.info/grammar.be.html) беларускай мовы. З дапамогай распрацаванага мною Python скрыпта ўсе словаформы кожнай часціны мовы былі сабраныя па асобных файлах ў фармаце: 
```
слова#слова#слова#слова#слова#...
```

## Спасылкі на выкарыстоўваемые матэрыялы
 - У праекце выкарыстоўваюцца слоўнікі Беларускага N-корпусу. 
Спасылка на іх рэпазітар Github - [GrammarDB](https://github.com/Belarus/GrammarDB). 
Граматычная база распаўсюджвацца па ліцэнзіі [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/).
Спасылка на ліцэнзію Граматычнай базы - [CC BY-SA 4.0](https://github.com/Belarus/GrammarDB/blob/master/docs/LICENSE.txt)
