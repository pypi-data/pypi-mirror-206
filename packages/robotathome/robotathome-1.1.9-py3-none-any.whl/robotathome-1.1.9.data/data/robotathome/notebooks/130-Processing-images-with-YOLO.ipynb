{"cells":[{"cell_type":"markdown","metadata":{"id":"ciZd3uHtZibP"},"source":["## Robot@Home 2 - Processing images with YOLO `v0.1`"]},{"cell_type":"markdown","metadata":{"id":"T6pEDhu4ZibR"},"source":["`R@H2 notebook series`   \n","\n","<a href=\"https://colab.research.google.com/github/goyoambrosio/RobotAtHome2/blob/master/notebooks/130-Processing-images-with-YOLO.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zEThg-ZeZibT"},"source":["### Getting started\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dreDRMBmZibU"},"source":["Install Robot@Home2 Toolbox using the Python package manager\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wf49vI45ZibU","executionInfo":{"status":"ok","timestamp":1681756412535,"user_tz":-120,"elapsed":9908,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"823c9feb-63bb-4ea5-9e85-f519dea20043"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting robotathome\n","  Downloading robotathome-1.1.3-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from robotathome) (1.26.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from robotathome) (2.27.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from robotathome) (8.1.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from robotathome) (1.5.3)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.9/dist-packages (from robotathome) (4.6.0)\n","Collecting loguru\n","  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from robotathome) (1.22.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from robotathome) (4.65.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->robotathome) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->robotathome) (2.8.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->robotathome) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->robotathome) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->robotathome) (2.0.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->robotathome) (1.16.0)\n","Installing collected packages: loguru, robotathome\n","Successfully installed loguru-0.7.0 robotathome-1.1.3\n"]}],"source":["!pip install robotathome"]},{"cell_type":"markdown","source":["Now, let's mount Google Drive (more info in [this notebook](https://colab.research.google.com/github/goyoambrosio/RobotAtHome2/blob/master/notebooks/05-Google-colab-drive.ipynb)) and instantiate the RobotAtHome class."],"metadata":{"id":"8wjqPLct9n4q"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ol-Tk7yEZibZ","executionInfo":{"status":"ok","timestamp":1681756442031,"user_tz":-120,"elapsed":24184,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"3ace8d3d-bd7f-4f18-acab-17e960919c59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m2023-04-17 18:34:01.489\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrobotathome.core.reader\u001b[0m:\u001b[36m__open_dataset\u001b[0m:\u001b[36m141\u001b[0m - \u001b[32m\u001b[1mConnection is established: rh.db\u001b[0m\n"]}],"source":["from google.colab import drive\n","from robotathome import RobotAtHome\n","from robotathome import logger, log, set_log_level\n","\n","# Let's mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Then copy the provided configutarion file to the current directory (/content)\n","!cp /content/drive/MyDrive/R@H2-2.0.3/notebooks/.rh .\n","\n","# And create an instance of the RobotAtHome class\n","try: \n","      rh = RobotAtHome()\n","except:\n","      logger.error(\"Something was wrong\")\n"]},{"cell_type":"markdown","metadata":{"id":"604BZ9isZibb"},"source":["### Iterating over RGBD images coming from multiple cameras\n","\n","\n"]},{"cell_type":"markdown","source":["We already know how to iterate over RGBD images coming from multiple cameras. We continue from the previous example where we have build a main loop to iterate and concatenate images."],"metadata":{"id":"QHtD14Zb7-Gm"}},{"cell_type":"code","source":["from robotathome import filter_sensor_observations\n","from robotathome import composed_RGBD_images\n","from robotathome import concat_images\n","from robotathome import process_image\n","\n","# cv2 causes some trouble to Colab so they provide a patch\n","# Usually you'll write: from cv2 import imshow\n","from google.colab.patches import cv2_imshow\n","\n","log.set_log_level('INFO')  # SUCCESS is the default\n","\n","# Fill the variables that constitutes selection filter\n","home_session_name = 'alma-s1'\n","home_subsession = 0\n","room_name = 'alma_masterroom1'\n","sensor_list = ['RGBD_3', 'RGBD_4', 'RGBD_1', 'RGBD_2'] # Left to right order\n","\n","# Get the labeled RGB-D observations dataframe\n","df = rh.get_sensor_observations('lblrgbd')\n","\n","# Filter the dataframe and get a dictionary with a dataframe per sensor\n","df_dict = filter_sensor_observations(rh, df,\n","                                     home_session_name,\n","                                     home_subsession,\n","                                     room_name,\n","                                     sensor_list)\n","\n","logger.info(f\"Labeled RGBD set: {len(df)} observations\")\n","for sensor_name in sensor_list:\n","    logger.info(f\"No. of RGBD observations int the filtered subset for the sensor {sensor_name}: {len(df_dict[sensor_name])} observations\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PcsHkq96Mhe","executionInfo":{"status":"ok","timestamp":1681756447692,"user_tz":-120,"elapsed":1798,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"68b1ce71-feb4-48a1-e8c2-c943aa6c34a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m2023-04-17 18:34:07.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 28>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLabeled RGBD set: 32937 observations\u001b[0m\n","\u001b[32m2023-04-17 18:34:07.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 29>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_3: 299 observations\u001b[0m\n","\u001b[32m2023-04-17 18:34:07.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 29>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_4: 299 observations\u001b[0m\n","\u001b[32m2023-04-17 18:34:07.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 29>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_1: 299 observations\u001b[0m\n","\u001b[32m2023-04-17 18:34:07.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 29>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_2: 299 observations\u001b[0m\n"]}]},{"cell_type":"markdown","source":["In Google Colab, reading files from the mounted drive takes time, so for this example we will select only a few images."],"metadata":{"id":"nujR5Pjv83cO"}},{"cell_type":"code","source":["# For this example, we will only select a few images\n","df_RGBD_N_only_some_frames = {}\n","for sensor_name in sensor_list:\n","    df_RGBD_N_only_some_frames[sensor_name] = df_dict[sensor_name][30:40] # ~ 1 sec"],"metadata":{"id":"319-2xsA8zqe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Processing with YOLO"],"metadata":{"id":"FF3hvHdylwNZ"}},{"cell_type":"markdown","source":["As we know from the previous example to make a video we need to write a function to get a video handler:"],"metadata":{"id":"u1SPnv6n_JXL"}},{"cell_type":"code","source":["import cv2 as cv\n","\n","def get_rh_video_handler(rh_dataset, filename, sensor_names):\n","    \"\"\"Return a video handler.\"\"\"\n","    sensor_size = rh_dataset.get_RGBD_sensor_size()\n","    fourcc = cv.VideoWriter_fourcc(*'MJPG')\n","    out = cv.VideoWriter(filename,\n","                          fourcc,\n","                          rh_dataset.get_RGBD_fps(),\n","                          (len(sensor_names)*sensor_size['w'], sensor_size['h']))\n","    return out\n"],"metadata":{"id":"1IjOBkKsnZA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We want to show the detection boxes from the YOLO process so we need to write some helper functions:"],"metadata":{"id":"-Ra6tE8xhg5u"}},{"cell_type":"code","source":["def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n","    # https://inside-machinelearning.com/en/bounding-boxes-python-function/\n","    lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n","    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n","    cv.rectangle(image, p1, p2, color, thickness=lw, lineType=cv.LINE_AA)\n","    if label:\n","        tf = max(lw - 1, 1)  # font thickness\n","        w, h = cv.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n","        outside = p1[1] - h >= 3\n","        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n","        cv.rectangle(image, p1, p2, color, -1, cv.LINE_AA)  # filled\n","        cv.putText(image,\n","                   label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n","                   0,\n","                   lw / 3,\n","                   txt_color,\n","                   thickness=tf,\n","                   lineType=cv.LINE_AA)\n","\n","\n","def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n","    # https://inside-machinelearning.com/en/bounding-boxes-python-function/\n","    # Define COCO Labels\n","    if labels == []:\n","        labels = {0: u'__background__', 1: u'person', 2: u'bicycle',3: u'car', 4: u'motorcycle', 5: u'airplane', 6: u'bus', 7: u'train', 8: u'truck', 9: u'boat', 10: u'traffic light', 11: u'fire hydrant', 12: u'stop sign', 13: u'parking meter', 14: u'bench', 15: u'bird', 16: u'cat', 17: u'dog', 18: u'horse', 19: u'sheep', 20: u'cow', 21: u'elephant', 22: u'bear', 23: u'zebra', 24: u'giraffe', 25: u'backpack', 26: u'umbrella', 27: u'handbag', 28: u'tie', 29: u'suitcase', 30: u'frisbee', 31: u'skis', 32: u'snowboard', 33: u'sports ball', 34: u'kite', 35: u'baseball bat', 36: u'baseball glove', 37: u'skateboard', 38: u'surfboard', 39: u'tennis racket', 40: u'bottle', 41: u'wine glass', 42: u'cup', 43: u'fork', 44: u'knife', 45: u'spoon', 46: u'bowl', 47: u'banana', 48: u'apple', 49: u'sandwich', 50: u'orange', 51: u'broccoli', 52: u'carrot', 53: u'hot dog', 54: u'pizza', 55: u'donut', 56: u'cake', 57: u'chair', 58: u'couch', 59: u'potted plant', 60: u'bed', 61: u'dining table', 62: u'toilet', 63: u'tv', 64: u'laptop', 65: u'mouse', 66: u'remote', 67: u'keyboard', 68: u'cell phone', 69: u'microwave', 70: u'oven', 71: u'toaster', 72: u'sink', 73: u'refrigerator', 74: u'book', 75: u'clock', 76: u'vase', 77: u'scissors', 78: u'teddy bear', 79: u'hair drier', 80: u'toothbrush'}\n","    # Define colors\n","    if colors == []:\n","        # colors = [(6, 112, 83), (253, 246, 160), (40, 132, 70), (205, 97, 162), (149, 196, 30), (106, 19, 161), (127, 175, 225), (115, 133, 176), (83, 156, 8), (182, 29, 77), (180, 11, 251), (31, 12, 123), (23, 6, 115), (167, 34, 31), (176, 216, 69), (110, 229, 222), (72, 183, 159), (90, 168, 209), (195, 4, 209), (135, 236, 21), (62, 209, 199), (87, 1, 70), (75, 40, 168), (121, 90, 126), (11, 86, 86), (40, 218, 53), (234, 76, 20), (129, 174, 192), (13, 18, 254), (45, 183, 149), (77, 234, 120), (182, 83, 207), (172, 138, 252), (201, 7, 159), (147, 240, 17), (134, 19, 233), (202, 61, 206), (177, 253, 26), (10, 139, 17), (130, 148, 106), (174, 197, 128), (106, 59, 168), (124, 180, 83), (78, 169, 4), (26, 79, 176), (185, 149, 150), (165, 253, 206), (220, 87, 0), (72, 22, 226), (64, 174, 4), (245, 131, 96), (35, 217, 142), (89, 86, 32), (80, 56, 196), (222, 136, 159), (145, 6, 219), (143, 132, 162), (175, 97, 221), (72, 3, 79), (196, 184, 237), (18, 210, 116), (8, 185, 81), (99, 181, 254), (9, 127, 123), (140, 94, 215), (39, 229, 121), (230, 51, 96), (84, 225, 33), (218, 202, 139), (129, 223, 182), (167, 46, 157), (15, 252, 5), (128, 103, 203), (197, 223, 199), (19, 238, 181), (64, 142, 167), (12, 203, 242), (69, 21, 41), (177, 184, 2), (35, 97, 56), (241, 22, 161)]\n","        colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n","\n","    # plot each boxes\n","    for box in boxes:\n","        # add score in label if score=True\n","        if score:\n","            label = labels[int(box[-1])+1] + \" \" + str(round(100 * float(box[-2]),1)) + \"%\"\n","        else:\n","            label = labels[int(box[-1])+1]\n","        # filter every box under conf threshold if conf threshold setted\n","        if conf:\n","            if box[-2] > conf:\n","                color = colors[int(box[-1])]\n","                box_label(image, box, label, color)\n","        else:\n","            color = colors[int(box[-1])]\n","            box_label(image, box, label, color)\n","    return image"],"metadata":{"id":"m_Qzpczzhn8i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For YOLO processing we need to install the ultralytics package:"],"metadata":{"id":"bExN7AGCiitm"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-jICXvoiqmK","executionInfo":{"status":"ok","timestamp":1681756494004,"user_tz":-120,"elapsed":6113,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"36495c64-39b6-455f-e48a-9ef9219ee4b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.81-py3-none-any.whl (527 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.0/527.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.15.1+cu118)\n","Collecting sentry-sdk\n","  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.4)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.0+cu118)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","Installing collected packages: sentry-sdk, thop, ultralytics\n","Successfully installed sentry-sdk-1.19.1 thop-0.1.1.post2209072238 ultralytics-8.0.81\n"]}]},{"cell_type":"markdown","source":["We are ready to write the function that we will pass to our main loop. The function `apply_model_ultralytics` detect objects in each image"],"metadata":{"id":"Weewm2WSl8R6"}},{"cell_type":"code","source":["def apply_model_ultralytics(img_dict, model):\n","    img_list = list(img_dict.values())\n","    img_list_result = []\n","    for img in img_list:\n","        results = model.predict(img, verbose=None)\n","        img_result = plot_bboxes(img, results[0].boxes.data)\n","        img_list_result.append(img_result)\n","    composed_img = cv.hconcat(img_list_result)\n","    return composed_img"],"metadata":{"id":"yD4ZlYB7jM4b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The main loop iterates over the images applying the prediction model. "],"metadata":{"id":"RUmliWHoEmvA"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import torch\n","\n","torch.device('cuda') # 'cpu','cuda'\n","model = YOLO(\"yolov8n.pt\")\n","\n","video_filename = 'myYOLOvideo.avi'\n","\n"," # Getting video handler\n","video_handler = get_rh_video_handler(rh,\n","                                     video_filename, #video_path_filename,\n","                                     sensor_list)\n","\n","# Iterate over the dictionary of dataframes, i.e. frame by frame\n","for (RGB_image_dict, D_image_dict) in composed_RGBD_images(rh, df_RGBD_N_only_some_frames):\n","    def f(img_dict):\n","        # return my_function(img_dict, par1,... parn)\n","        return apply_model_ultralytics(img_dict, model)\n","\n","    # Apply f to img_dict\n","    resulting_img = process_image(f, RGB_image_dict)\n","    # Add the resulting image to the video\n","    video_handler.write(resulting_img)\n","# Closing video file\n","video_handler.release()"],"metadata":{"id":"8kl7zWfo73kP","executionInfo":{"status":"ok","timestamp":1681756594863,"user_tz":-120,"elapsed":93782,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04441299-ec29-414d-8527-5ce2c2562db1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n","100%|██████████| 6.23M/6.23M [00:00<00:00, 154MB/s]\n"]}]},{"cell_type":"code","source":["[_, _, _, wspc_path, _] = rh.get_path_vars()\n","!cp $video_filename $wspc_path\n","!ls $wspc_path/*.avi"],"metadata":{"id":"8rXTwQRYAOX4","executionInfo":{"status":"ok","timestamp":1681756603277,"user_tz":-120,"elapsed":957,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7cee4579-c989-4600-b9b7-411c5928fbd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/drive/MyDrive/Colab Notebooks/myvideo.avi'\n","'/content/drive/MyDrive/Colab Notebooks/myYOLOvideo.avi'\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"org":null,"colab":{"provenance":[{"file_id":"1y_KP5DFCGQsb6xKa8qCO18r4XtnG6uv1","timestamp":1681739401424},{"file_id":"1xiMi36FLzyDylIsDA0n5d1TYU5b1pqB0","timestamp":1681723811033},{"file_id":"1Lw0BEQW37voYxhvAkW0NxPVRaOK7LXNt","timestamp":1681660869898},{"file_id":"1rtOgdZ3f58kHJlwqK9l5KAvt3bN7ftiF","timestamp":1681324410249}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}