"""Utilities for handling gene sets."""
import datetime
import glob
import json
import logging
from typing import List, Optional, Tuple

import requests
import yaml
from cachier import cachier
from oaklib import BasicOntologyInterface
from pydantic import BaseModel

from ontogpt.templates.class_enrichment import ClassEnrichmentResult

ENTITY_ID = str
SYMBOL = str
DESCRIPTION = str
GENE_TUPLE = Tuple[ENTITY_ID, SYMBOL, DESCRIPTION]


class GeneSet(BaseModel):
    """A set of genes."""

    name: str
    gene_symbols: Optional[List[str]] = None
    gene_ids: Optional[List[str]] = None
    taxon: str = "human"
    taxon_id: Optional[str] = None
    description: Optional[str] = None
    source: Optional[str] = None
    source_url: Optional[str] = None
    target_term_ids: Optional[List[str]] = None


class GeneSetCollection(BaseModel):
    """A collection of gene sets."""

    gene_sets: List[GeneSet]


class EnrichmentPayload(BaseModel):
    """Payload for enrichment."""

    prompt: str = None
    """The prompt to use for the summarization task (only filled for LLMs)."""

    response_text: str = None
    """The response text from the summarization task (only filled for LLMs)."""

    truncation_factor: float = None
    """Fraction of gene descriptions retained after trimming to fit token limit."""

    summary: str = None
    """The summary of the gene set generated by the LLM."""

    term_strings: List[str] = []
    """The raw term labels parsed from the LLM completion payload"""

    term_ids: List[str] = []
    """The normalized terms"""

    ontological_synopsis: bool = None
    """True if the gene descriptions used the ontological synopsis"""

    combined_synopsis: bool = None
    """True if the gene descriptions used both ontological and narrative synopses"""

    annotations: bool = None
    """True if the gene descriptions used the annotations (vs latent KB)"""

    response_token_length: int = None
    """The number of tokens in the response text"""

    model: str = None
    """The model used for the summarization task (only filled for LLMs)."""

    method: str = None
    """The method used for the summarization task."""

    enrichment_results: List[ClassEnrichmentResult] = None
    """Enrichment results (only filled for non-LLMs)"""


def parse_gene_set(input_path: str, format: str = None) -> GeneSet:
    """
    Parse a gene set from a file.

    Accepts:

    - yaml (native gene set format; recommended)
    - json (msigdb format)
    - txt (one gene symbol per line)

    This does no normalization of gene symbols or ids.

    """
    if format is None:
        format = input_path.split(".")[-1]
    if format == "yaml":
        with open(input_path, "r") as f:
            gene_set = GeneSet(**yaml.safe_load(f))
    elif format == "json" or format == "msigdb":
        with open(input_path, "r") as f:
            name, msig = list(json.load(f).items())[0]
            gene_set = GeneSet(name=name, gene_symbols=msig["geneSymbols"])
    elif format == "txt":
        with open(input_path, "r") as f:
            gene_symbols = [line.strip() for line in f.readlines()]
            gene_set = GeneSet(name=input_path, gene_symbols=gene_symbols)
    else:
        raise ValueError(f"Unknown format {format}")
    return gene_set


def load_gene_sets(
    path: str, ontology_adapter: BasicOntologyInterface = None, strict=False
) -> GeneSetCollection:
    """Load gene sets from a folder.

    If ontology_adapter is provided, gene symbols will be converted to gene ids and vice versa.
    """
    gene_sets = []
    for input_path in glob.glob(f"{path}/*.yaml"):
        gene_set = parse_gene_set(input_path)
        gene_sets.append(gene_set)
        if not gene_set.gene_ids and not gene_set.gene_symbols:
            raise ValueError(f"Gene set {gene_set.name} has no gene symbols or ids")
        populate_ids_and_symbols(gene_set, ontology_adapter, strict)
    return GeneSetCollection(gene_sets=gene_sets)


def populate_ids_and_symbols(
    gene_set: GeneSet, ontology_adapter: BasicOntologyInterface = None, strict=False
):
    if ontology_adapter:
        if not gene_set.gene_ids:
            print(f"Fetching ids for {len(gene_set.gene_symbols)} genes")
            gene_set.gene_ids = []
            for sym in gene_set.gene_symbols:
                ids = ontology_adapter.curies_by_label(sym)
                if strict and len(ids) != 1:
                    raise ValueError(f"Could not find a single id for symbol {sym}")
                # hack! normalize casing
                gene_set.gene_ids.extend([id.upper() for id in ids])
        if not gene_set.gene_symbols:
            # print(f"Fetching labels for {len(gene_set.gene_ids)} genes")
            gene_set.gene_symbols = []
            for id in gene_set.gene_ids:
                # HACK! lowercase the id to avoid issues with obo-dv-ingest
                lbl = ontology_adapter.label(id.lower())
                # print(f"{id} -> {lbl}")
                if lbl:
                    gene_set.gene_symbols.append(lbl)
                else:
                    if strict:
                        raise ValueError(f"Could not find a label for id {id}")


@cachier(stale_after=datetime.timedelta(days=7))
def gene_info(id: ENTITY_ID) -> Tuple[SYMBOL, DESCRIPTION, DESCRIPTION]:
    url = f"https://www.alliancegenome.org/api/gene/{id}"
    logging.info(f"Fetching gene summary from {url}")
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError(f"Error fetching issues: {response.status_code} // {response.text}")
    obj = response.json()
    symbol = obj["symbol"]
    return symbol, obj["geneSynopsis"], obj["automatedGeneSynopsis"]
