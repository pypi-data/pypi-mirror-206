{"cells":[{"cell_type":"markdown","metadata":{"id":"ciZd3uHtZibP"},"source":["# Robot@Home 2 - Segmentation with Detectron2 `v0.1`"]},{"cell_type":"markdown","metadata":{"id":"T6pEDhu4ZibR"},"source":["`R@H2 notebook series`   \n","\n","<a href=\"https://colab.research.google.com/github/goyoambrosio/RobotAtHome2/blob/master/notebooks/150-Segmentation-with-Detectron2.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n","\n"]},{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"ofEnStDYx1nb"}},{"cell_type":"markdown","source":["This notebook presents a new example of data processing performed on our mobile robotic dataset. Specifically, we demonstrate how to perform segmentation using Detectron2, a ground-up rewrite of Facebook AI Research's Detectron object detection platform."],"metadata":{"id":"DqOSRUW3vSQW"}},{"cell_type":"markdown","source":["## Downloading R@H2 locally"],"metadata":{"id":"IBelUUb_hW6U"}},{"cell_type":"markdown","source":["As we have already shown in previous examples, we can install the dataset in the local storage space of the virtual machine, which allows us to apply functions locally and execute them at the highest processing speed.\n","\n","\n","Next cell will download R@H2 dataset in the local storage. It will take ~8 minutes."],"metadata":{"id":"vqVbY8f1weTu"}},{"cell_type":"code","source":["!mkdir -p /content/R@H2/files\n","!mkdir -p /content/WORKSPACE\n","\n","%cd /content/WORKSPACE\n","!gdown 1qmvhcPrMTNKtWpGfWQHUPVqE67356N6I # .rh\n","%cd /content/R@H2\n","!gdown 17Mt2KzwJMjvagrP1X-Q0SVbAGUc1M7TW # Robot@Home2_db.tgz\n","!gdown 1zdG4zA55MrQ6r12L_Fg2KIJgnpD479rf # Robot@Home2_files.tgz\n","\n","!echo Decompressing database\n","!tar -xzf Robot@Home2_db.tgz\n","!echo Decompressing files\n","!echo '|================================================> 100%'\n","!tar -xzf Robot@Home2_files.tgz -C ./files --checkpoint=.50000\n","\n","!rm /content/R@H2/Robot@Home2_db.tgz\n","!rm /content/R@H2/Robot@Home2_files.tgz\n","\n","%cd /content/WORKSPACE"],"metadata":{"id":"2UIEa6PYfupA","executionInfo":{"status":"ok","timestamp":1682973177319,"user_tz":-120,"elapsed":409200,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"af01c90f-5a4d-42f3-9adc-02580f0f779e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/WORKSPACE\n","Downloading...\n","From: https://drive.google.com/uc?id=1qmvhcPrMTNKtWpGfWQHUPVqE67356N6I\n","To: /content/WORKSPACE/.rh\n","100% 211/211 [00:00<00:00, 1.36MB/s]\n","/content/R@H2\n","Downloading...\n","From: https://drive.google.com/uc?id=17Mt2KzwJMjvagrP1X-Q0SVbAGUc1M7TW\n","To: /content/R@H2/Robot@Home2_db.tgz\n","100% 517M/517M [00:07<00:00, 69.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1zdG4zA55MrQ6r12L_Fg2KIJgnpD479rf\n","To: /content/R@H2/Robot@Home2_files.tgz\n","100% 12.5G/12.5G [01:34<00:00, 133MB/s]\n","Decompressing database\n","Decompressing files\n","|================================================> 100%\n","................................................../content/WORKSPACE\n"]}]},{"cell_type":"markdown","source":["We have finished the process with the following folder structure:\n","\n","    /content\n","     ├─── /R@H2\n","     │    │   └── /files\n","     │    │      ├── /rgbd\n","     │    │      └── /scene\n","     │    └────── rh.db\n","     └─── /WORKSPACE\n","           └── .rh"],"metadata":{"id":"ddl8yYok0ZYa"}},{"cell_type":"markdown","source":["## Mounting Google Drive"],"metadata":{"id":"f2eOsZHy6iCn"}},{"cell_type":"markdown","source":["Remember that Colab's storage is not persistent, so we optionally mount our Google Drive to provide a permanent storage space."],"metadata":{"id":"PJv7TnXO65HY"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"060XmRFaVTFw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682790575490,"user_tz":-120,"elapsed":18453,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"44c7d23b-2cd5-48b2-ef7b-8cd6fd16ac59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Installing needed packages"],"metadata":{"id":"ARzm-qdIycag"}},{"cell_type":"markdown","source":["Now, we will install needed packages. We'll start with the Robot@Home package.\n"],"metadata":{"id":"Q7H7_yQ4z5m3"}},{"cell_type":"code","source":["!pip install robotathome --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBYLjlSkzX7F","executionInfo":{"status":"ok","timestamp":1682973191818,"user_tz":-120,"elapsed":6871,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"a7ba55c0-8b04-416d-ad7e-ac06fe415bf7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import robotathome\n","print(robotathome.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IG5mUzznBSJo","executionInfo":{"status":"ok","timestamp":1682973267560,"user_tz":-120,"elapsed":1749,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"b0d9b084-b738-4b82-f9f1-666993936f35"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["1.1.8\n"]}]},{"cell_type":"markdown","source":["For Detectron2 you will have to wait another 4 minutes."],"metadata":{"id":"slu3KgataTWK"}},{"cell_type":"code","source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHbKVU7uUOoO","executionInfo":{"status":"ok","timestamp":1682973552105,"user_tz":-120,"elapsed":272800,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"c49b223f-56bf-4ebd-a3d9-39d21e136bec"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["## Main code"],"metadata":{"id":"RtHu8KSpa_c1"}},{"cell_type":"markdown","source":["Ok, now that we've set up our environment, we'll proceed to the important code. In this example, we assume that you have some experience with Robot@Home2 and Python, so we won't go into all the details."],"metadata":{"id":"LuJY1arVTZxw"}},{"cell_type":"markdown","source":["First, we import neccesary libraries. [Tqdm](https://https://tqdm.github.io/) is a library that is used for creating Python Progress Bars."],"metadata":{"id":"zIahPta-Ugxn"}},{"cell_type":"code","source":["# import some common libraries\n","import os\n","import datetime as dt\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","# cv2 causes some trouble to Colab so they provide a patch\n","# Usually you'll write: from cv2 import imshow\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"7iUUhoFFOgYg","executionInfo":{"status":"ok","timestamp":1682973665302,"user_tz":-120,"elapsed":310,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Robot@Home2"],"metadata":{"id":"ZOCr0yajN11v"}},{"cell_type":"markdown","source":["It's time for Robot@Home2. As usual, we import some necessary functions from the package."],"metadata":{"id":"zaeTbuvOVbFB"}},{"cell_type":"code","source":["from robotathome import RobotAtHome\n","from robotathome import filter_sensor_observations\n","from robotathome import composed_RGBD_images, concat_images, process_image\n","from robotathome import logger, log"],"metadata":{"id":"uVDU4K8OnlO9","executionInfo":{"status":"ok","timestamp":1682973672039,"user_tz":-120,"elapsed":215,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["As we run experiments, we generate a large number of videos. Naming videos sometimes becomes a tedious task. For this reason, we then introduce the next function to which we pass the dataset parameters and it returns a concatenated string with the date and time data so that no two names are the same. An example could be something like: `pare-s1_0_pare_livingroom1_RGBD_1_20230429202717.mp4`"],"metadata":{"id":"UjKnmA5lVsm8"}},{"cell_type":"code","source":["def get_video_filename(rh_dataset: RobotAtHome,\n","                       home_session_name: str,\n","                       home_subsession: str,\n","                       room_name: str,\n","                       sensor_name: str):\n","    \"\"\"Return a filename composed by arguments and current time.\n","\n","    The filename extension is .avi\n","    \"\"\"\n","    video_filename = ''.join(\n","        [\n","            home_session_name,\n","            '_', str(home_subsession),\n","            '_', room_name,\n","            '_', sensor_name,\n","            dt.datetime.now().strftime(\"_%Y%m%d%H%M%S\"),\n","            '.mp4'\n","        ])\n","\n","    [_, _, _, wspc_path, _] = rh_dataset.get_path_vars()\n","    video_path_filename = os.path.abspath(os.path.join(wspc_path,\n","                                                       video_filename))\n","    return video_path_filename"],"metadata":{"id":"w_bDhNTBjznp","executionInfo":{"status":"ok","timestamp":1682973674137,"user_tz":-120,"elapsed":311,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Like previous examples, we introduce a function to get a video handler."],"metadata":{"id":"b0HMxmOr4OSW"}},{"cell_type":"code","source":["def get_rh_video_handler(rh_dataset, filename, sensor_names):\n","    \"\"\"Return a video handler.\"\"\"\n","    sensor_size = rh_dataset.get_RGBD_sensor_size()\n","    fourcc = cv.VideoWriter_fourcc(*'MJPG')\n","    # fourcc = cv.VideoWriter_fourcc(*'mp4v')\n","    out = cv.VideoWriter(filename,\n","                          fourcc,\n","                          rh_dataset.get_RGBD_fps(),\n","                          (len(sensor_names)*sensor_size['w'], sensor_size['h']))\n","    return out"],"metadata":{"id":"p1Bv7GSumf3n","executionInfo":{"status":"ok","timestamp":1682973684875,"user_tz":-120,"elapsed":657,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["As we already know, to work with the dataset we instantiante the RobotAtHome class and extract a subset of RGBD observations."],"metadata":{"id":"pJ_TcgXZ4qu0"}},{"cell_type":"code","source":["log.set_log_level('INFO')  # SUCCESS is the default\n","\n","# Fill the variables that constitutes selection filter\n","home_session_name = 'pare-s1'\n","home_subsession = 0\n","room_name = 'pare_livingroom1'\n","sensor_list = ['RGBD_3', 'RGBD_4', 'RGBD_1', 'RGBD_2'] # Left to right order\n","\n","# Create an instance of the RobotAtHome class\n","try: \n","      rh = RobotAtHome()\n","except:\n","      logger.error(\"Something was wrong\")\n","\n","# Get the labeled RGB-D observations dataframe\n","df = rh.get_sensor_observations('lblrgbd')\n","\n","# Filter the dataframe and get a dictionary with a dataframe per sensor\n","df_dict = filter_sensor_observations(rh, df,\n","                                     home_session_name,\n","                                     home_subsession,\n","                                     room_name,\n","                                     sensor_list)\n","\n","logger.info(f\"Labeled RGBD set: {len(df)} observations\")\n","for sensor_name in sensor_list:\n","    logger.info(f\"No. of RGBD observations int the filtered subset for the sensor {sensor_name}: {len(df_dict[sensor_name])} observations\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86Pb4sV5yuTS","executionInfo":{"status":"ok","timestamp":1682973687936,"user_tz":-120,"elapsed":625,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"a114bd42-8fac-4733-9396-cba1bb11d0ff"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m2023-05-01 20:41:27.224\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mrobotathome.core.reader\u001b[0m:\u001b[36m__open_dataset\u001b[0m:\u001b[36m141\u001b[0m - \u001b[32m\u001b[1mConnection is established: rh.db\u001b[0m\n","\u001b[32m2023-05-01 20:41:27.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 25>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mLabeled RGBD set: 32937 observations\u001b[0m\n","\u001b[32m2023-05-01 20:41:27.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 26>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_3: 292 observations\u001b[0m\n","\u001b[32m2023-05-01 20:41:27.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 26>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_4: 292 observations\u001b[0m\n","\u001b[32m2023-05-01 20:41:27.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 26>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_1: 292 observations\u001b[0m\n","\u001b[32m2023-05-01 20:41:27.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 26>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mNo. of RGBD observations int the filtered subset for the sensor RGBD_2: 292 observations\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Detectron2"],"metadata":{"id":"mKA0I9yaN9mx"}},{"cell_type":"markdown","source":["We are now ready to work with Detectron2. We start by importing the necessary functions."],"metadata":{"id":"0wNUNK676Dg7"}},{"cell_type":"code","source":["# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common detectron2 utilities\n","from detectron2.config import get_cfg\n","from detectron2 import model_zoo\n","\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.video_visualizer import VideoVisualizer\n","from detectron2.utils.visualizer import ColorMode, Visualizer\n","from detectron2.data import MetadataCatalog"],"metadata":{"id":"5js6lw0-NqDV","executionInfo":{"status":"ok","timestamp":1682973698693,"user_tz":-120,"elapsed":3505,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["We can easily configure our model for different tasks. Next two cells are examples of that. The first one creates a model configuration for object detection. The resulting video will show classic boxes around the detected objects. On the other hand, the next cell creates a model for object segmentation. The resulting video will show colored regions with the segmented objects.\n","\n","You have to run only the chosen one."],"metadata":{"id":"un5-Lbuv6b8D"}},{"cell_type":"code","source":["# Create config for object detection\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")"],"metadata":{"id":"i25YoF3sNYHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create config for object segmentation\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")"],"metadata":{"id":"anC-bUYZtqHb","executionInfo":{"status":"ok","timestamp":1682973706326,"user_tz":-120,"elapsed":229,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Next cell, creates the predictor for the previously chosen configuration. A `visualizer` is also created to allow bounding boxes o colored regions to be displayed over each image."],"metadata":{"id":"-LADGxZa8DWR"}},{"cell_type":"code","source":["# Create predictor\n","predictor = DefaultPredictor(cfg)\n","\n","# Initialize visualizer\n","v = VideoVisualizer(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), ColorMode.IMAGE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gy0xlfUQtlqK","executionInfo":{"status":"ok","timestamp":1682973712512,"user_tz":-120,"elapsed":3438,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"ac4bcf2d-d778-4904-9423-71f7f0227f80"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[05/01 20:41:50 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["model_final_f10217.pkl: 178MB [00:01, 120MB/s]                           \n"]}]},{"cell_type":"markdown","source":["In the next cell, we define a function to apply the predictor (also known as object detection/segmentation) to the compose image of the selected camera sensors."],"metadata":{"id":"imUSV2Rd9Q4Y"}},{"cell_type":"code","source":["def apply_model_detectron_composed(img_dict, predictor, v):\n","    img_list = list(img_dict.values())\n","    img_list_result = []\n","    for img in img_list:\n","        # Append image from sensor to img_list\n","        img_list_result.append(img)\n","    composed_img = cv.hconcat(img_list_result)\n","\n","    # Make prediction\n","    outputs = predictor(composed_img)\n","    # Make sure the img is colored\n","    composed_img = cv.cvtColor(composed_img, cv.COLOR_RGB2BGR)\n","    # Draw a visualization of the predictions using the video visualizer\n","    visualization = v.draw_instance_predictions(composed_img, outputs[\"instances\"].to(\"cpu\"))\n","    # Convert Matplotlib RGB format to OpenCV BGR format\n","    processed_img = cv.cvtColor(visualization.get_image(), cv.COLOR_RGB2BGR)\n","    return processed_img"],"metadata":{"id":"5gjuN9pPvkgi","executionInfo":{"status":"ok","timestamp":1682973715521,"user_tz":-120,"elapsed":220,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Main loop"],"metadata":{"id":"kf2DVkgeODSS"}},{"cell_type":"markdown","source":["We are now going to apply the predictor to all selected images in the data set. Next we show the main loop where the previous function is passed as an argument to be applied to each image.\n","\n","Thanks to the `tqdm` function, the expected number of iterations and progress will be displayed."],"metadata":{"id":"01nOYzdR-Bdr"}},{"cell_type":"code","source":["# Building video filename\n","video_filename = get_video_filename(rh,\n","                                    home_session_name,\n","                                    home_subsession,\n","                                    room_name,\n","                                    '-'.join(sensor_list))\n","# Getting video handler\n","video_handler = get_rh_video_handler(rh,\n","                                     video_filename,\n","                                     sensor_list)\n","\n","# #############################################\n","#                Main loop\n","# #############################################\n","\n","# Iterate over the dictionary of dataframes, i.e. frame by frame\n","for (RGB_image_dict, D_image_dict) in tqdm(composed_RGBD_images(\n","                                           rh,\n","                                           df_dict),\n","                                           desc =f\"Wait for {len(df_dict[sensor_list[0]])} iterations\"):\n","    def f(img_dict):\n","        # return my_function(img_dict, par1,... parn)\n","        return apply_model_detectron_composed(img_dict, predictor, v)\n","    # Apply f to img_dict\n","    resulting_img = process_image(f, RGB_image_dict)\n","    # cv2_imshow(resulting_img)\n","    video_handler.write(resulting_img)\n","\n","# Closing video file\n","video_handler.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAaICQ54K0JG","executionInfo":{"status":"ok","timestamp":1682973948393,"user_tz":-120,"elapsed":99389,"user":{"displayName":"Gregorio Ambrosio Cestero","userId":"14960755229665189412"}},"outputId":"65521d34-85ce-4fa1-ad85-6d0e168a18a7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Wait for 292 iterations: 292it [01:39,  2.94it/s]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"org":null,"colab":{"provenance":[{"file_id":"14sh9ThcEMyGMU9qrm0vHQ2nssTrICha0","timestamp":1682008102360},{"file_id":"1QRHr58F0o1dyIye2NP44lRwuWdcYl0LL","timestamp":1681846166456},{"file_id":"1y_KP5DFCGQsb6xKa8qCO18r4XtnG6uv1","timestamp":1681739401424},{"file_id":"1xiMi36FLzyDylIsDA0n5d1TYU5b1pqB0","timestamp":1681723811033},{"file_id":"1Lw0BEQW37voYxhvAkW0NxPVRaOK7LXNt","timestamp":1681660869898},{"file_id":"1rtOgdZ3f58kHJlwqK9l5KAvt3bN7ftiF","timestamp":1681324410249}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}