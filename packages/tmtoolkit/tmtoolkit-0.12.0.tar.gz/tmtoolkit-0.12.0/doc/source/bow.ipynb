{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Bag-of-Words representation\n",
    "\n",
    "The [bow module](api.rst#tmtoolkit-bow) in tmtoolkit contains several functions for working with Bag-of-Words (BoW) representations of documents. It's divided into two sub-modules: [bow.bow_stats](api.rst#module-tmtoolkit.bow.bow_stats) and [bow.dtm](api.rst#module-tmtoolkit.bow.dtm). The former implements several statistics and transformations for BoW representations, the latter contains functions to create and convert sparse or dense document-term matrices (DTMs).\n",
    "\n",
    "Most of the functions in both sub-modules accept and/or return sparse DTMs. The [previous chapter](preprocessing.ipynb) contained a section about what sparse DTMs are and [how they can be generated with tmtoolkit](preprocessing.ipynb#Generating-a-sparse-document-term-matrix-(DTM))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example document-term matrix\n",
    "\n",
    "Before we start with the [bow.dtm](api.rst#module-tmtoolkit.bow.dtm) module, we will generate a sparse DTM from a small example corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:30.484890Z",
     "iopub.status.busy": "2023-04-05T15:36:30.484688Z",
     "iopub.status.idle": "2023-04-05T15:36:32.473438Z",
     "shell.execute_reply": "2023-04-05T15:36:32.472980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus with 5 documents in English\n",
      "> NewsArticles-119 (110 tokens): Is a ' seven - day NHS ' feasible ?    The \" seven...\n",
      "> NewsArticles-1206 (135 tokens): Man critical after four - car collision in Dublin ...\n",
      "> NewsArticles-3016 (621 tokens): Farron likens PM 's politics to Trump 's and Putin...\n",
      "> NewsArticles-2058 (1174 tokens): Merkel : ' Only if Europe is doing well , will Ger...\n",
      "> NewsArticles-3665 (1158 tokens): Presidential elections in France have never been a...\n",
      "total number of tokens: 3198 / vocabulary size: 1170\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(20191113)   # to make the sampling reproducible\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "from tmtoolkit.corpus import Corpus, print_summary\n",
    "\n",
    "corpus = Corpus.from_builtin_corpus('en-NewsArticles', sample=5)\n",
    "print_summary(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ a preprocessing pipeline that removes a lot of information from our original data in order to obtain a very condensed DTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.491306Z",
     "iopub.status.busy": "2023-04-05T15:36:32.491110Z",
     "iopub.status.idle": "2023-04-05T15:36:32.516687Z",
     "shell.execute_reply": "2023-04-05T15:36:32.516229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>lemma</th>\n",
       "      <th>like_num</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NewsArticles-119</td>\n",
       "      <td>0</td>\n",
       "      <td>day</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>day</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NewsArticles-119</td>\n",
       "      <td>1</td>\n",
       "      <td>nhs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NHS</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NewsArticles-119</td>\n",
       "      <td>2</td>\n",
       "      <td>day</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>day</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NewsArticles-119</td>\n",
       "      <td>3</td>\n",
       "      <td>nhs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NHS</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewsArticles-119</td>\n",
       "      <td>4</td>\n",
       "      <td>pledge</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pledge</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>NewsArticles-3665</td>\n",
       "      <td>349</td>\n",
       "      <td>article</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>NewsArticles-3665</td>\n",
       "      <td>350</td>\n",
       "      <td>author</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>NewsArticles-3665</td>\n",
       "      <td>351</td>\n",
       "      <td>al</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Al</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>NewsArticles-3665</td>\n",
       "      <td>352</td>\n",
       "      <td>jazeera</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jazeera</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>NewsArticles-3665</td>\n",
       "      <td>353</td>\n",
       "      <td>policy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>policy.-</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   doc  position    token  is_punct  is_stop     lemma  \\\n",
       "0     NewsArticles-119         0      day     False    False       day   \n",
       "1     NewsArticles-119         1      nhs     False    False       NHS   \n",
       "2     NewsArticles-119         2      day     False    False       day   \n",
       "3     NewsArticles-119         3      nhs     False    False       NHS   \n",
       "4     NewsArticles-119         4   pledge     False    False    pledge   \n",
       "..                 ...       ...      ...       ...      ...       ...   \n",
       "914  NewsArticles-3665       349  article     False    False   article   \n",
       "915  NewsArticles-3665       350   author     False    False    author   \n",
       "916  NewsArticles-3665       351       al     False    False        Al   \n",
       "917  NewsArticles-3665       352  jazeera     False    False   Jazeera   \n",
       "918  NewsArticles-3665       353   policy     False    False  policy.-   \n",
       "\n",
       "     like_num    pos  tag  \n",
       "0       False   NOUN   NN  \n",
       "1       False  PROPN  NNP  \n",
       "2       False   NOUN   NN  \n",
       "3       False  PROPN  NNP  \n",
       "4       False   NOUN   NN  \n",
       "..        ...    ...  ...  \n",
       "914     False   NOUN   NN  \n",
       "915     False   NOUN   NN  \n",
       "916     False  PROPN  NNP  \n",
       "917     False  PROPN  NNP  \n",
       "918     False   NOUN   NN  \n",
       "\n",
       "[919 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.corpus import (lemmatize, filter_for_pos, to_lowercase,\n",
    "    remove_punctuation, filter_clean_tokens, remove_common_tokens,\n",
    "    tokens_table)\n",
    "\n",
    "\n",
    "corpus_norm = lemmatize(corpus, inplace=False)\n",
    "filter_for_pos(corpus_norm, 'N')\n",
    "to_lowercase(corpus_norm)\n",
    "remove_punctuation(corpus_norm)\n",
    "filter_clean_tokens(corpus_norm, remove_shorter_than=2)\n",
    "# remove tokens that occur in all documents\n",
    "remove_common_tokens(corpus_norm, df_threshold=5, proportions=0)\n",
    "                        \n",
    "tokens_table(corpus_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retained all documents, but removed more than half of the token types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.518194Z",
     "iopub.status.busy": "2023-04-05T15:36:32.518086Z",
     "iopub.status.idle": "2023-04-05T15:36:32.520778Z",
     "shell.execute_reply": "2023-04-05T15:36:32.520465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 516)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.corpus import vocabulary_size\n",
    "\n",
    "len(corpus_norm), vocabulary_size(corpus_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the document labels and vocabulary and convert them to NumPy arrays, because such arrays allow advanced indexing methods such as boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.522213Z",
     "iopub.status.busy": "2023-04-05T15:36:32.522025Z",
     "iopub.status.idle": "2023-04-05T15:36:32.524664Z",
     "shell.execute_reply": "2023-04-05T15:36:32.524356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NewsArticles-119', 'NewsArticles-1206', 'NewsArticles-2058',\n",
       "       'NewsArticles-3016', 'NewsArticles-3665'], dtype='<U17')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.corpus import doc_labels\n",
    "\n",
    "labels = np.array(doc_labels(corpus_norm))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.525956Z",
     "iopub.status.busy": "2023-04-05T15:36:32.525774Z",
     "iopub.status.idle": "2023-04-05T15:36:32.528611Z",
     "shell.execute_reply": "2023-04-05T15:36:32.528297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['110pm', '70', 'abuse', 'access', 'accession', 'accusation', 'act',\n",
       "       'addition', 'address', 'administration'], dtype='<U16')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.corpus import vocabulary\n",
    "\n",
    "vocab = np.array(vocabulary(corpus_norm))\n",
    "vocab[:10]  # only showing the first 10 token types here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the sparse DTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.529886Z",
     "iopub.status.busy": "2023-04-05T15:36:32.529763Z",
     "iopub.status.idle": "2023-04-05T15:36:32.534491Z",
     "shell.execute_reply": "2023-04-05T15:36:32.534143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x516 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 576 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.corpus import dtm\n",
    "\n",
    "mat = dtm(corpus_norm)\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a sparse DTM `mat`, an array of document labels `labels` that represent the rows of the DTM and an array of vocabulary tokens `vocab` that represent the columns of the DTM. We will use this data for the remainder of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `bow.dtm` module\n",
    "\n",
    "This module is quite small. Most importantly, there's a function to convert a DTM to a pandas DataFrame, [dtm_to_dataframe](api.rst#tmtoolkit.bow.dtm.dtm_to_dataframe). Note that the generated dataframe is *dense*, i.e. it uses up (much) more memory than the input DTM.\n",
    "\n",
    "Let's generate a dataframe from our DTM, the document labels and the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.535904Z",
     "iopub.status.busy": "2023-04-05T15:36:32.535750Z",
     "iopub.status.idle": "2023-04-05T15:36:32.542186Z",
     "shell.execute_reply": "2023-04-05T15:36:32.541835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110pm</th>\n",
       "      <th>70</th>\n",
       "      <th>abuse</th>\n",
       "      <th>access</th>\n",
       "      <th>accession</th>\n",
       "      <th>accusation</th>\n",
       "      <th>act</th>\n",
       "      <th>addition</th>\n",
       "      <th>address</th>\n",
       "      <th>administration</th>\n",
       "      <th>...</th>\n",
       "      <th>wing</th>\n",
       "      <th>winston</th>\n",
       "      <th>work</th>\n",
       "      <th>workers</th>\n",
       "      <th>world</th>\n",
       "      <th>wound</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>yucel</th>\n",
       "      <th>�</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NewsArticles-119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-2058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-3016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-3665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   110pm  70  abuse  access  accession  accusation  act  \\\n",
       "NewsArticles-119       0   0      0       1          0           0    0   \n",
       "NewsArticles-1206      1   1      0       0          0           0    0   \n",
       "NewsArticles-2058      0   0      0       0          1           1    0   \n",
       "NewsArticles-3016      0   0      1       0          0           0    0   \n",
       "NewsArticles-3665      0   0      0       1          0           0    1   \n",
       "\n",
       "                   addition  address  administration  ...  wing  winston  \\\n",
       "NewsArticles-119          0        0               0  ...     0        0   \n",
       "NewsArticles-1206         0        0               0  ...     0        0   \n",
       "NewsArticles-2058         0        0               0  ...     1        0   \n",
       "NewsArticles-3016         0        0               0  ...     0        1   \n",
       "NewsArticles-3665         1        1               1  ...     1        0   \n",
       "\n",
       "                   work  workers  world  wound  year  york  yucel  �  \n",
       "NewsArticles-119      0        0      0      0     0     0      0  0  \n",
       "NewsArticles-1206     0        0      0      0     0     0      0  2  \n",
       "NewsArticles-2058     2        1      0      0     2     0      2  0  \n",
       "NewsArticles-3016     0        0      3      1     0     1      0  0  \n",
       "NewsArticles-3665     0        0      0      0     1     0      0  0  \n",
       "\n",
       "[5 rows x 516 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.dtm import dtm_to_dataframe\n",
    "\n",
    "dtm_to_dataframe(mat, labels, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that an index with the document labels was created and that the vocabulary tokens become the column names.\n",
    "\n",
    "You can combine tmtoolkit with [Gensim](https://radimrehurek.com/gensim/). The `bow.dtm` module provides several functions to convert data between both packages:\n",
    "\n",
    "- [dtm_and_vocab_to_gensim_corpus_and_dict](api.rst#tmtoolkit.bow.dtm.dtm_and_vocab_to_gensim_corpus_and_dict): converts a (sparse) DTM and a vocabulary list to a *Gensim Corpus* and *Gensim Dictionary*\n",
    "- [dtm_to_gensim_corpus](api.rst#tmtoolkit.bow.dtm.dtm_to_gensim_corpus): convert a (sparse) DTM only to a *Gensim Corpus*\n",
    "- [gensim_corpus_to_dtm](api.rst#tmtoolkit.bow.dtm.gensim_corpus_to_dtm): converts a *Gensim Corpus* object to a sparse DTM in COO format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `bow.bow_stats` module\n",
    "\n",
    "This module provides several statistics and transformations for sparse or dense DTMs.\n",
    "\n",
    "### Document lengths, document and term frequencies, token co-occurrences\n",
    "\n",
    "Let's start with the [doc_lengths](api.rst#tmtoolkit.bow.bow_stats.doc_lengths) function, which simply gives the number of tokens per document (i.e. the row-wise sum of the DTM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.543611Z",
     "iopub.status.busy": "2023-04-05T15:36:32.543483Z",
     "iopub.status.idle": "2023-04-05T15:36:32.546134Z",
     "shell.execute_reply": "2023-04-05T15:36:32.545793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 38,  40, 330, 157, 354])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_lengths\n",
    "\n",
    "doc_lengths(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned array is aligned to the document labels `labels` so we can see that the last document, \"NewsArticles-3665\", is the one with the most tokens. Or to do it computationally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.547419Z",
     "iopub.status.busy": "2023-04-05T15:36:32.547250Z",
     "iopub.status.idle": "2023-04-05T15:36:32.549965Z",
     "shell.execute_reply": "2023-04-05T15:36:32.549615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NewsArticles-3665'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[doc_lengths(mat).argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `doc_lengths` gives the row-wise sum across the DTM, [term_frequencies](api.rst#tmtoolkit.bow.bow_stats.term_frequencies) gives the column-wise sum. This means it returns an array of the length of the vocabulary's size where each entry in that array reflects the number of occurrences of the respective vocabulary token (aka term).\n",
    "\n",
    "Let's calculate that measure, get its maximum and the token type(s) for that maximum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.551514Z",
     "iopub.status.busy": "2023-04-05T15:36:32.551202Z",
     "iopub.status.idle": "2023-04-05T15:36:32.554636Z",
     "shell.execute_reply": "2023-04-05T15:36:32.554310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, array(['medium'], dtype='<U16'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import term_frequencies\n",
    "\n",
    "term_freq = term_frequencies(mat)\n",
    "(term_freq.max(), vocab[term_freq == term_freq.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to calculate the proportional frequency, i.e. normalize the counts by the overall number of tokens via `proportions=1`. Alternatively, `proportions=2` gives you log proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.556110Z",
     "iopub.status.busy": "2023-04-05T15:36:32.555857Z",
     "iopub.status.idle": "2023-04-05T15:36:32.558988Z",
     "shell.execute_reply": "2023-04-05T15:36:32.558659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['candidate', 'eu', 'macron', 'medium', 'merkel', 'refugee'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_prop = term_frequencies(mat, proportions=1)\n",
    "vocab[term_prop >= 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [doc_frequencies](api.rst#tmtoolkit.bow.bow_stats.doc_frequencies) returns how often each token in the vocabulary occurs at least *n* times per document. You can control *n* per parameter `min_val` which is set to `1` by default. The returned array is aligned with the vocabulary. Here, we calculate the document frequency with the default value `min_val=1`, extract the maximum document frequency and see which of the tokens in the `vocab` array reach the maximum document frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.560485Z",
     "iopub.status.busy": "2023-04-05T15:36:32.560218Z",
     "iopub.status.idle": "2023-04-05T15:36:32.563638Z",
     "shell.execute_reply": "2023-04-05T15:36:32.563291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, array(['minister'], dtype='<U16'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_frequencies\n",
    "\n",
    "df = doc_frequencies(mat)\n",
    "max_df = df.max()\n",
    "max_df, vocab[df == max_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the maximum document frequency is 4 and only the token \"minister\" reaches that document frequency. This means only \"minister\" is mentioned across 4 documents at least once (because `min_val` is `1`). Remember that during preprocessing, we removed all tokens that occur across *all* five documents, hence there can't be a vocabulary token with a document frequency of 5.\n",
    "\n",
    "Let's see which vocabulary tokens occur within a single document at least 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.565472Z",
     "iopub.status.busy": "2023-04-05T15:36:32.565204Z",
     "iopub.status.idle": "2023-04-05T15:36:32.568962Z",
     "shell.execute_reply": "2023-04-05T15:36:32.568464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['candidate', 'eu', 'macron', 'medium', 'merkel', 'refugee'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = doc_frequencies(mat, min_val=10)\n",
    "vocab[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the *co-document frequency* or *token co-occurrence* matrix via [codoc_frequencies](api.rst#tmtoolkit.bow.bow_stats.codoc_frequencies). This measures how often each pair of vocabulary tokens occurs at least *n* times together in the same document. Again, you can control *n* per parameter `min_val` which is set to `1` by default. The result is a sparse matrix of shape *vocabulary size* by *vocabulary size*. The columns and rows give the pairs of tokens from the vocabulary.\n",
    "\n",
    "Let's generate a co-document frequency matrix and convert it to a dense representation, because our further operations don't support sparse matrices.\n",
    "\n",
    "A co-document frequency matrix is symmetric along the diagonal, because co-occurrence between a pair `(token1, token2)` is always the same as between `(token2, token1)`. We want to filter out the duplicate pairs and for that use [np.triu](https://docs.scipy.org/doc/numpy/reference/generated/numpy.triu.html) to take only the upper triangle of the matrix, i.e. set all values in the lower triangle including the matrix diagonal to zero (`k=1` does this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.570601Z",
     "iopub.status.busy": "2023-04-05T15:36:32.570338Z",
     "iopub.status.idle": "2023-04-05T15:36:32.575664Z",
     "shell.execute_reply": "2023-04-05T15:36:32.575230Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import codoc_frequencies\n",
    "\n",
    "codoc_mat = codoc_frequencies(mat).todense()\n",
    "codoc_upper = np.triu(codoc_mat, k=1)\n",
    "codoc_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a list that contains the pairs of tokens that occur together in at least two documents (`codoc_upper > 1`) together with their co-document frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.577140Z",
     "iopub.status.busy": "2023-04-05T15:36:32.576885Z",
     "iopub.status.idle": "2023-04-05T15:36:32.590642Z",
     "shell.execute_reply": "2023-04-05T15:36:32.590147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('government', 'minister', 3),\n",
       " ('minister', 'time', 3),\n",
       " ('access', 'channel', 2),\n",
       " ('access', 'day', 2),\n",
       " ('access', 'minister', 2),\n",
       " ('access', 'news', 2),\n",
       " ('april', 'author', 2),\n",
       " ('april', 'co', 2),\n",
       " ('april', 'critic', 2),\n",
       " ('april', 'distribution', 2),\n",
       " ('april', 'heart', 2),\n",
       " ('april', 'law', 2),\n",
       " ('april', 'minister', 2),\n",
       " ('april', 'policy', 2),\n",
       " ('april', 'question', 2),\n",
       " ('april', 'right', 2),\n",
       " ('april', 'state', 2),\n",
       " ('april', 'support', 2),\n",
       " ('april', 'system', 2),\n",
       " ('april', 'time', 2),\n",
       " ('april', 'way', 2),\n",
       " ('april', 'wing', 2),\n",
       " ('april', 'year', 2),\n",
       " ('attack', 'brexit', 2),\n",
       " ('attack', 'comment', 2),\n",
       " ('attack', 'consensus', 2),\n",
       " ('attack', 'country', 2),\n",
       " ('attack', 'deal', 2),\n",
       " ('attack', 'donald', 2),\n",
       " ('attack', 'end', 2),\n",
       " ('attack', 'eu', 2),\n",
       " ('attack', 'europe', 2),\n",
       " ('attack', 'government', 2),\n",
       " ('attack', 'leader', 2),\n",
       " ('attack', 'minister', 2),\n",
       " ('attack', 'party', 2),\n",
       " ('attack', 'president', 2),\n",
       " ('attack', 'referendum', 2),\n",
       " ('attack', 'spring', 2),\n",
       " ('attack', 'sunday', 2),\n",
       " ('attack', 'supporter', 2),\n",
       " ('attack', 'time', 2),\n",
       " ('attack', 'trade', 2),\n",
       " ('attack', 'trump', 2),\n",
       " ('attack', 'value', 2),\n",
       " ('author', 'co', 2),\n",
       " ('author', 'critic', 2),\n",
       " ('author', 'distribution', 2),\n",
       " ('author', 'heart', 2),\n",
       " ('author', 'law', 2),\n",
       " ('author', 'minister', 2),\n",
       " ('author', 'policy', 2),\n",
       " ('author', 'question', 2),\n",
       " ('author', 'right', 2),\n",
       " ('author', 'state', 2),\n",
       " ('author', 'support', 2),\n",
       " ('author', 'system', 2),\n",
       " ('author', 'time', 2),\n",
       " ('author', 'way', 2),\n",
       " ('author', 'wing', 2),\n",
       " ('author', 'year', 2),\n",
       " ('brexit', 'comment', 2),\n",
       " ('brexit', 'consensus', 2),\n",
       " ('brexit', 'country', 2),\n",
       " ('brexit', 'deal', 2),\n",
       " ('brexit', 'donald', 2),\n",
       " ('brexit', 'end', 2),\n",
       " ('brexit', 'eu', 2),\n",
       " ('brexit', 'europe', 2),\n",
       " ('brexit', 'government', 2),\n",
       " ('brexit', 'leader', 2),\n",
       " ('brexit', 'minister', 2),\n",
       " ('brexit', 'party', 2),\n",
       " ('brexit', 'president', 2),\n",
       " ('brexit', 'referendum', 2),\n",
       " ('brexit', 'spring', 2),\n",
       " ('brexit', 'sunday', 2),\n",
       " ('brexit', 'supporter', 2),\n",
       " ('brexit', 'time', 2),\n",
       " ('brexit', 'trade', 2),\n",
       " ('brexit', 'trump', 2),\n",
       " ('brexit', 'value', 2),\n",
       " ('channel', 'day', 2),\n",
       " ('channel', 'minister', 2),\n",
       " ('channel', 'news', 2),\n",
       " ('co', 'critic', 2),\n",
       " ('co', 'distribution', 2),\n",
       " ('co', 'heart', 2),\n",
       " ('co', 'law', 2),\n",
       " ('co', 'minister', 2),\n",
       " ('co', 'policy', 2),\n",
       " ('co', 'question', 2),\n",
       " ('co', 'right', 2),\n",
       " ('co', 'state', 2),\n",
       " ('co', 'support', 2),\n",
       " ('co', 'system', 2),\n",
       " ('co', 'time', 2),\n",
       " ('co', 'way', 2),\n",
       " ('co', 'wing', 2),\n",
       " ('co', 'year', 2),\n",
       " ('comment', 'consensus', 2),\n",
       " ('comment', 'country', 2),\n",
       " ('comment', 'deal', 2),\n",
       " ('comment', 'donald', 2),\n",
       " ('comment', 'end', 2),\n",
       " ('comment', 'eu', 2),\n",
       " ('comment', 'europe', 2),\n",
       " ('comment', 'government', 2),\n",
       " ('comment', 'leader', 2),\n",
       " ('comment', 'minister', 2),\n",
       " ('comment', 'party', 2),\n",
       " ('comment', 'president', 2),\n",
       " ('comment', 'referendum', 2),\n",
       " ('comment', 'spring', 2),\n",
       " ('comment', 'sunday', 2),\n",
       " ('comment', 'supporter', 2),\n",
       " ('comment', 'time', 2),\n",
       " ('comment', 'trade', 2),\n",
       " ('comment', 'trump', 2),\n",
       " ('comment', 'value', 2),\n",
       " ('consensus', 'country', 2),\n",
       " ('consensus', 'deal', 2),\n",
       " ('consensus', 'donald', 2),\n",
       " ('consensus', 'end', 2),\n",
       " ('consensus', 'eu', 2),\n",
       " ('consensus', 'europe', 2),\n",
       " ('consensus', 'government', 2),\n",
       " ('consensus', 'leader', 2),\n",
       " ('consensus', 'minister', 2),\n",
       " ('consensus', 'party', 2),\n",
       " ('consensus', 'president', 2),\n",
       " ('consensus', 'referendum', 2),\n",
       " ('consensus', 'spring', 2),\n",
       " ('consensus', 'sunday', 2),\n",
       " ('consensus', 'supporter', 2),\n",
       " ('consensus', 'time', 2),\n",
       " ('consensus', 'trade', 2),\n",
       " ('consensus', 'trump', 2),\n",
       " ('consensus', 'value', 2),\n",
       " ('country', 'deal', 2),\n",
       " ('country', 'donald', 2),\n",
       " ('country', 'end', 2),\n",
       " ('country', 'eu', 2),\n",
       " ('country', 'europe', 2),\n",
       " ('country', 'government', 2),\n",
       " ('country', 'leader', 2),\n",
       " ('country', 'minister', 2),\n",
       " ('country', 'party', 2),\n",
       " ('country', 'president', 2),\n",
       " ('country', 'referendum', 2),\n",
       " ('country', 'spring', 2),\n",
       " ('country', 'sunday', 2),\n",
       " ('country', 'supporter', 2),\n",
       " ('country', 'time', 2),\n",
       " ('country', 'trade', 2),\n",
       " ('country', 'trump', 2),\n",
       " ('country', 'value', 2),\n",
       " ('critic', 'distribution', 2),\n",
       " ('critic', 'heart', 2),\n",
       " ('critic', 'law', 2),\n",
       " ('critic', 'minister', 2),\n",
       " ('critic', 'policy', 2),\n",
       " ('critic', 'question', 2),\n",
       " ('critic', 'right', 2),\n",
       " ('critic', 'state', 2),\n",
       " ('critic', 'support', 2),\n",
       " ('critic', 'system', 2),\n",
       " ('critic', 'time', 2),\n",
       " ('critic', 'way', 2),\n",
       " ('critic', 'wing', 2),\n",
       " ('critic', 'year', 2),\n",
       " ('day', 'minister', 2),\n",
       " ('day', 'news', 2),\n",
       " ('deal', 'donald', 2),\n",
       " ('deal', 'end', 2),\n",
       " ('deal', 'eu', 2),\n",
       " ('deal', 'europe', 2),\n",
       " ('deal', 'government', 2),\n",
       " ('deal', 'leader', 2),\n",
       " ('deal', 'minister', 2),\n",
       " ('deal', 'party', 2),\n",
       " ('deal', 'president', 2),\n",
       " ('deal', 'referendum', 2),\n",
       " ('deal', 'spring', 2),\n",
       " ('deal', 'sunday', 2),\n",
       " ('deal', 'supporter', 2),\n",
       " ('deal', 'time', 2),\n",
       " ('deal', 'trade', 2),\n",
       " ('deal', 'trump', 2),\n",
       " ('deal', 'value', 2),\n",
       " ('debate', 'le', 2),\n",
       " ('debate', 'minister', 2),\n",
       " ('debate', 'pen', 2),\n",
       " ('debate', 'position', 2),\n",
       " ('debate', 'society', 2),\n",
       " ('debate', 'time', 2),\n",
       " ('debate', 'view', 2),\n",
       " ('debate', 'vision', 2),\n",
       " ('distribution', 'heart', 2),\n",
       " ('distribution', 'law', 2),\n",
       " ('distribution', 'minister', 2),\n",
       " ('distribution', 'policy', 2),\n",
       " ('distribution', 'question', 2),\n",
       " ('distribution', 'right', 2),\n",
       " ('distribution', 'state', 2),\n",
       " ('distribution', 'support', 2),\n",
       " ('distribution', 'system', 2),\n",
       " ('distribution', 'time', 2),\n",
       " ('distribution', 'way', 2),\n",
       " ('distribution', 'wing', 2),\n",
       " ('distribution', 'year', 2),\n",
       " ('donald', 'end', 2),\n",
       " ('donald', 'eu', 2),\n",
       " ('donald', 'europe', 2),\n",
       " ('donald', 'government', 2),\n",
       " ('donald', 'leader', 2),\n",
       " ('donald', 'minister', 2),\n",
       " ('donald', 'party', 2),\n",
       " ('donald', 'president', 2),\n",
       " ('donald', 'referendum', 2),\n",
       " ('donald', 'spring', 2),\n",
       " ('donald', 'sunday', 2),\n",
       " ('donald', 'supporter', 2),\n",
       " ('donald', 'time', 2),\n",
       " ('donald', 'trade', 2),\n",
       " ('donald', 'trump', 2),\n",
       " ('donald', 'value', 2),\n",
       " ('end', 'eu', 2),\n",
       " ('end', 'europe', 2),\n",
       " ('end', 'government', 2),\n",
       " ('end', 'leader', 2),\n",
       " ('end', 'minister', 2),\n",
       " ('end', 'party', 2),\n",
       " ('end', 'president', 2),\n",
       " ('end', 'referendum', 2),\n",
       " ('end', 'spring', 2),\n",
       " ('end', 'sunday', 2),\n",
       " ('end', 'supporter', 2),\n",
       " ('end', 'time', 2),\n",
       " ('end', 'trade', 2),\n",
       " ('end', 'trump', 2),\n",
       " ('end', 'value', 2),\n",
       " ('eu', 'europe', 2),\n",
       " ('eu', 'government', 2),\n",
       " ('eu', 'leader', 2),\n",
       " ('eu', 'minister', 2),\n",
       " ('eu', 'party', 2),\n",
       " ('eu', 'president', 2),\n",
       " ('eu', 'referendum', 2),\n",
       " ('eu', 'spring', 2),\n",
       " ('eu', 'sunday', 2),\n",
       " ('eu', 'supporter', 2),\n",
       " ('eu', 'time', 2),\n",
       " ('eu', 'trade', 2),\n",
       " ('eu', 'trump', 2),\n",
       " ('eu', 'value', 2),\n",
       " ('europe', 'government', 2),\n",
       " ('europe', 'leader', 2),\n",
       " ('europe', 'minister', 2),\n",
       " ('europe', 'party', 2),\n",
       " ('europe', 'president', 2),\n",
       " ('europe', 'referendum', 2),\n",
       " ('europe', 'spring', 2),\n",
       " ('europe', 'sunday', 2),\n",
       " ('europe', 'supporter', 2),\n",
       " ('europe', 'time', 2),\n",
       " ('europe', 'trade', 2),\n",
       " ('europe', 'trump', 2),\n",
       " ('europe', 'value', 2),\n",
       " ('government', 'leader', 2),\n",
       " ('government', 'party', 2),\n",
       " ('government', 'people', 2),\n",
       " ('government', 'president', 2),\n",
       " ('government', 'prime', 2),\n",
       " ('government', 'referendum', 2),\n",
       " ('government', 'spring', 2),\n",
       " ('government', 'sunday', 2),\n",
       " ('government', 'supporter', 2),\n",
       " ('government', 'theresa', 2),\n",
       " ('government', 'time', 2),\n",
       " ('government', 'trade', 2),\n",
       " ('government', 'trump', 2),\n",
       " ('government', 'value', 2),\n",
       " ('heart', 'law', 2),\n",
       " ('heart', 'minister', 2),\n",
       " ('heart', 'policy', 2),\n",
       " ('heart', 'question', 2),\n",
       " ('heart', 'right', 2),\n",
       " ('heart', 'state', 2),\n",
       " ('heart', 'support', 2),\n",
       " ('heart', 'system', 2),\n",
       " ('heart', 'time', 2),\n",
       " ('heart', 'way', 2),\n",
       " ('heart', 'wing', 2),\n",
       " ('heart', 'year', 2),\n",
       " ('information', 'station', 2),\n",
       " ('law', 'minister', 2),\n",
       " ('law', 'policy', 2),\n",
       " ('law', 'question', 2),\n",
       " ('law', 'right', 2),\n",
       " ('law', 'state', 2),\n",
       " ('law', 'support', 2),\n",
       " ('law', 'system', 2),\n",
       " ('law', 'time', 2),\n",
       " ('law', 'way', 2),\n",
       " ('law', 'wing', 2),\n",
       " ('law', 'year', 2),\n",
       " ('le', 'minister', 2),\n",
       " ('le', 'pen', 2),\n",
       " ('le', 'position', 2),\n",
       " ('le', 'society', 2),\n",
       " ('le', 'time', 2),\n",
       " ('le', 'view', 2),\n",
       " ('le', 'vision', 2),\n",
       " ('leader', 'minister', 2),\n",
       " ('leader', 'party', 2),\n",
       " ('leader', 'president', 2),\n",
       " ('leader', 'referendum', 2),\n",
       " ('leader', 'spring', 2),\n",
       " ('leader', 'sunday', 2),\n",
       " ('leader', 'supporter', 2),\n",
       " ('leader', 'time', 2),\n",
       " ('leader', 'trade', 2),\n",
       " ('leader', 'trump', 2),\n",
       " ('leader', 'value', 2),\n",
       " ('minister', 'news', 2),\n",
       " ('minister', 'party', 2),\n",
       " ('minister', 'pen', 2),\n",
       " ('minister', 'people', 2),\n",
       " ('minister', 'policy', 2),\n",
       " ('minister', 'position', 2),\n",
       " ('minister', 'president', 2),\n",
       " ('minister', 'prime', 2),\n",
       " ('minister', 'question', 2),\n",
       " ('minister', 'referendum', 2),\n",
       " ('minister', 'right', 2),\n",
       " ('minister', 'society', 2),\n",
       " ('minister', 'spring', 2),\n",
       " ('minister', 'state', 2),\n",
       " ('minister', 'sunday', 2),\n",
       " ('minister', 'support', 2),\n",
       " ('minister', 'supporter', 2),\n",
       " ('minister', 'system', 2),\n",
       " ('minister', 'theresa', 2),\n",
       " ('minister', 'trade', 2),\n",
       " ('minister', 'trump', 2),\n",
       " ('minister', 'value', 2),\n",
       " ('minister', 'view', 2),\n",
       " ('minister', 'vision', 2),\n",
       " ('minister', 'way', 2),\n",
       " ('minister', 'wing', 2),\n",
       " ('minister', 'year', 2),\n",
       " ('party', 'president', 2),\n",
       " ('party', 'referendum', 2),\n",
       " ('party', 'spring', 2),\n",
       " ('party', 'sunday', 2),\n",
       " ('party', 'supporter', 2),\n",
       " ('party', 'time', 2),\n",
       " ('party', 'trade', 2),\n",
       " ('party', 'trump', 2),\n",
       " ('party', 'value', 2),\n",
       " ('pen', 'position', 2),\n",
       " ('pen', 'society', 2),\n",
       " ('pen', 'time', 2),\n",
       " ('pen', 'view', 2),\n",
       " ('pen', 'vision', 2),\n",
       " ('policy', 'question', 2),\n",
       " ('policy', 'right', 2),\n",
       " ('policy', 'state', 2),\n",
       " ('policy', 'support', 2),\n",
       " ('policy', 'system', 2),\n",
       " ('policy', 'time', 2),\n",
       " ('policy', 'way', 2),\n",
       " ('policy', 'wing', 2),\n",
       " ('policy', 'year', 2),\n",
       " ('position', 'society', 2),\n",
       " ('position', 'time', 2),\n",
       " ('position', 'view', 2),\n",
       " ('position', 'vision', 2),\n",
       " ('president', 'referendum', 2),\n",
       " ('president', 'spring', 2),\n",
       " ('president', 'sunday', 2),\n",
       " ('president', 'supporter', 2),\n",
       " ('president', 'time', 2),\n",
       " ('president', 'trade', 2),\n",
       " ('president', 'trump', 2),\n",
       " ('president', 'value', 2),\n",
       " ('prime', 'theresa', 2),\n",
       " ('question', 'right', 2),\n",
       " ('question', 'state', 2),\n",
       " ('question', 'support', 2),\n",
       " ('question', 'system', 2),\n",
       " ('question', 'time', 2),\n",
       " ('question', 'way', 2),\n",
       " ('question', 'wing', 2),\n",
       " ('question', 'year', 2),\n",
       " ('referendum', 'spring', 2),\n",
       " ('referendum', 'sunday', 2),\n",
       " ('referendum', 'supporter', 2),\n",
       " ('referendum', 'time', 2),\n",
       " ('referendum', 'trade', 2),\n",
       " ('referendum', 'trump', 2),\n",
       " ('referendum', 'value', 2),\n",
       " ('right', 'state', 2),\n",
       " ('right', 'support', 2),\n",
       " ('right', 'system', 2),\n",
       " ('right', 'time', 2),\n",
       " ('right', 'way', 2),\n",
       " ('right', 'wing', 2),\n",
       " ('right', 'year', 2),\n",
       " ('society', 'time', 2),\n",
       " ('society', 'view', 2),\n",
       " ('society', 'vision', 2),\n",
       " ('spring', 'sunday', 2),\n",
       " ('spring', 'supporter', 2),\n",
       " ('spring', 'time', 2),\n",
       " ('spring', 'trade', 2),\n",
       " ('spring', 'trump', 2),\n",
       " ('spring', 'value', 2),\n",
       " ('state', 'support', 2),\n",
       " ('state', 'system', 2),\n",
       " ('state', 'time', 2),\n",
       " ('state', 'way', 2),\n",
       " ('state', 'wing', 2),\n",
       " ('state', 'year', 2),\n",
       " ('sunday', 'supporter', 2),\n",
       " ('sunday', 'time', 2),\n",
       " ('sunday', 'trade', 2),\n",
       " ('sunday', 'trump', 2),\n",
       " ('sunday', 'value', 2),\n",
       " ('support', 'system', 2),\n",
       " ('support', 'time', 2),\n",
       " ('support', 'way', 2),\n",
       " ('support', 'wing', 2),\n",
       " ('support', 'year', 2),\n",
       " ('supporter', 'time', 2),\n",
       " ('supporter', 'trade', 2),\n",
       " ('supporter', 'trump', 2),\n",
       " ('supporter', 'value', 2),\n",
       " ('system', 'time', 2),\n",
       " ('system', 'way', 2),\n",
       " ('system', 'wing', 2),\n",
       " ('system', 'year', 2),\n",
       " ('time', 'trade', 2),\n",
       " ('time', 'trump', 2),\n",
       " ('time', 'value', 2),\n",
       " ('time', 'view', 2),\n",
       " ('time', 'vision', 2),\n",
       " ('time', 'way', 2),\n",
       " ('time', 'wing', 2),\n",
       " ('time', 'year', 2),\n",
       " ('trade', 'trump', 2),\n",
       " ('trade', 'value', 2),\n",
       " ('trump', 'value', 2),\n",
       " ('view', 'vision', 2),\n",
       " ('way', 'wing', 2),\n",
       " ('way', 'year', 2),\n",
       " ('wing', 'year', 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting_pairs = [(vocab[t1], vocab[t2], codoc_upper[t1, t2])\n",
    "                     for t1, t2 in zip(*np.where(codoc_upper > 1))]\n",
    "# sort by codoc freq. in desc. order\n",
    "sorted(interesting_pairs, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you have a matrix that encodes some quantity between a *pair of items*, you can use [pairwise_max_table](api.rst#tmtoolkit.utils.pairwise_max_table) to visualize the results for the maximum values of each pair. Such a matrix must always be a square matrix. The above co-document frequency is a valid candidate to use for this function. Note that the output is different since we don't restrict the matrix to the strict upper triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.592436Z",
     "iopub.status.busy": "2023-04-05T15:36:32.592177Z",
     "iopub.status.idle": "2023-04-05T15:36:32.598264Z",
     "shell.execute_reply": "2023-04-05T15:36:32.597915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>minister</td>\n",
       "      <td>minister</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>time</td>\n",
       "      <td>minister</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>government</td>\n",
       "      <td>government</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>end</td>\n",
       "      <td>attack</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>deal</td>\n",
       "      <td>attack</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>fear</td>\n",
       "      <td>abuse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>favour</td>\n",
       "      <td>access</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>farron</td>\n",
       "      <td>abuse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>fact</td>\n",
       "      <td>abuse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>�</td>\n",
       "      <td>110pm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x           y  value\n",
       "282    minister    minister      4\n",
       "462        time    minister      3\n",
       "200  government  government      3\n",
       "154         end      attack      2\n",
       "118        deal      attack      2\n",
       "..          ...         ...    ...\n",
       "178        fear       abuse      1\n",
       "177      favour      access      1\n",
       "176      farron       abuse      1\n",
       "175        fact       abuse      1\n",
       "515           �       110pm      1\n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.utils import pairwise_max_table\n",
    "\n",
    "pairwise_max_table(codoc_mat, labels=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, however, also use the upper triangular matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.599855Z",
     "iopub.status.busy": "2023-04-05T15:36:32.599716Z",
     "iopub.status.idle": "2023-04-05T15:36:32.605592Z",
     "shell.execute_reply": "2023-04-05T15:36:32.605239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>minister</td>\n",
       "      <td>time</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>government</td>\n",
       "      <td>minister</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>channel</td>\n",
       "      <td>day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>co</td>\n",
       "      <td>critic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>spring</td>\n",
       "      <td>sunday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>favour</td>\n",
       "      <td>federation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>farron</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>fact</td>\n",
       "      <td>farron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>facebook</td>\n",
       "      <td>fence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>year</td>\n",
       "      <td>yucel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x           y  value\n",
       "282    minister        time      3\n",
       "200  government    minister      3\n",
       "74      channel         day      2\n",
       "79           co      critic      2\n",
       "427      spring      sunday      2\n",
       "..          ...         ...    ...\n",
       "177      favour  federation      1\n",
       "176      farron        fear      1\n",
       "175        fact      farron      1\n",
       "174    facebook       fence      1\n",
       "511        year       yucel      1\n",
       "\n",
       "[512 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_max_table(codoc_upper, labels=vocab, skip_zeros=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sorted lists and datatables according to term frequency\n",
    "\n",
    "When working with DTMs, it's often helpful to rank terms per document according to their frequency. This is what [sorted_terms](api.rst#tmtoolkit.bow.bow_stats.sorted_terms) does for you. It further allows to specify the sorting order (the default is descending order via `ascending=False`) and several limits:\n",
    "\n",
    "- `lo_thresh` for the minimum term frequency\n",
    "- `hi_thresh` for the maximum term frequency\n",
    "- `top_n` for the maximum number of terms per document\n",
    "\n",
    "Let's display the top three tokens per document by frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.606955Z",
     "iopub.status.busy": "2023-04-05T15:36:32.606826Z",
     "iopub.status.idle": "2023-04-05T15:36:32.610491Z",
     "shell.execute_reply": "2023-04-05T15:36:32.610152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('day', 3), ('nhs', 2), ('bbc', 2)],\n",
       " [('car', 4), ('garda', 4), ('collision', 3)],\n",
       " [('merkel', 14), ('refugee', 13), ('eu', 13)],\n",
       " [('politic', 7), ('party', 6), ('farron', 5)],\n",
       " [('medium', 23), ('candidate', 19), ('macron', 15)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import sorted_terms\n",
    "\n",
    "sorted_terms(mat, vocab, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list for each document (this means the output is aligned with the document labels `doc_labels`), with three pairs of `(token, frequency)` each. It's also possible to get this data as dataframe via [sorted_terms_table](api.rst#tmtoolkit.bow.bow_stats.sorted_terms_table), which gives a better overview and also includes labels for the documents. It accepts the same parameters for sorting and limitting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.612143Z",
     "iopub.status.busy": "2023-04-05T15:36:32.611795Z",
     "iopub.status.idle": "2023-04-05T15:36:32.619481Z",
     "shell.execute_reply": "2023-04-05T15:36:32.619106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-119</th>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nhs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-1206</th>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collision</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-2058</th>\n",
       "      <th>1</th>\n",
       "      <td>merkel</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refugee</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3016</th>\n",
       "      <th>1</th>\n",
       "      <td>politic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>party</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>farron</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3665</th>\n",
       "      <th>1</th>\n",
       "      <td>medium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macron</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            token  value\n",
       "doc               rank                  \n",
       "NewsArticles-119  1           day      3\n",
       "                  2           nhs      2\n",
       "                  3           bbc      2\n",
       "NewsArticles-1206 1           car      4\n",
       "                  2         garda      4\n",
       "                  3     collision      3\n",
       "NewsArticles-2058 1        merkel     14\n",
       "                  2       refugee     13\n",
       "                  3            eu     13\n",
       "NewsArticles-3016 1       politic      7\n",
       "                  2         party      6\n",
       "                  3        farron      5\n",
       "NewsArticles-3665 1        medium     23\n",
       "                  2     candidate     19\n",
       "                  3        macron     15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import sorted_terms_table\n",
    "\n",
    "sorted_terms_table(mat, vocab, labels, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.620735Z",
     "iopub.status.busy": "2023-04-05T15:36:32.620634Z",
     "iopub.status.idle": "2023-04-05T15:36:32.627198Z",
     "shell.execute_reply": "2023-04-05T15:36:32.626861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NewsArticles-2058</th>\n",
       "      <th>1</th>\n",
       "      <td>merkel</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refugee</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>germany</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turkey</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>europe</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NewsArticles-3016</th>\n",
       "      <th>1</th>\n",
       "      <td>politic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>party</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NewsArticles-3665</th>\n",
       "      <th>1</th>\n",
       "      <td>medium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macron</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>france</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>election</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>le</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coverage</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            token  value\n",
       "doc               rank                  \n",
       "NewsArticles-2058 1        merkel     14\n",
       "                  2       refugee     13\n",
       "                  3            eu     13\n",
       "                  4       germany      8\n",
       "                  5       country      8\n",
       "                  6        turkey      6\n",
       "                  7        europe      6\n",
       "NewsArticles-3016 1       politic      7\n",
       "                  2         party      6\n",
       "NewsArticles-3665 1        medium     23\n",
       "                  2     candidate     19\n",
       "                  3        macron     15\n",
       "                  4        france      9\n",
       "                  5      election      9\n",
       "                  6            le      7\n",
       "                  7      coverage      6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_terms_table(mat, vocab, labels, lo_thresh=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency–inverse document frequency transformation (tf-idf)\n",
    "\n",
    "[Term frequency–inverse document frequency transformation (tf-idf)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a matrix transformation that is often applied to DTMs in order to reflect the importance of a token to a document. The `bow_stats` module provides the function [tfidf](api.rst#tmtoolkit.bow.bow_stats.tfidf) for this. When the input is a sparse matrix, and the calculation supports operating on sparce matrices, the output will also be a sparse matrix, which means that the tf-idf transformation is implemented in a very memory-efficient way.\n",
    "\n",
    "Let's apply tf-idf to our DTM using the default way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.628574Z",
     "iopub.status.busy": "2023-04-05T15:36:32.628458Z",
     "iopub.status.idle": "2023-04-05T15:36:32.631459Z",
     "shell.execute_reply": "2023-04-05T15:36:32.631132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 576 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import tfidf\n",
    "\n",
    "tfidf_mat = tfidf(mat)\n",
    "tfidf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output is a sparse matrix. Let's have a look at its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.632969Z",
     "iopub.status.busy": "2023-04-05T15:36:32.632856Z",
     "iopub.status.idle": "2023-04-05T15:36:32.635557Z",
     "shell.execute_reply": "2023-04-05T15:36:32.635201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "        [0.03132, 0.03132, 0.     , ..., 0.     , 0.     , 0.06264],\n",
       "        [0.     , 0.     , 0.     , ..., 0.     , 0.00759, 0.     ],\n",
       "        [0.     , 0.     , 0.00798, ..., 0.00798, 0.     , 0.     ],\n",
       "        [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can also pass this matrix to `sorted_terms_table` and observe that some rankings have changed in comparison to the untransformed DTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.636770Z",
     "iopub.status.busy": "2023-04-05T15:36:32.636653Z",
     "iopub.status.idle": "2023-04-05T15:36:32.644123Z",
     "shell.execute_reply": "2023-04-05T15:36:32.643756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-119</th>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>0.077434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc</td>\n",
       "      <td>0.065935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victoria</td>\n",
       "      <td>0.065935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-1206</th>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.125276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garda</td>\n",
       "      <td>0.125276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collision</td>\n",
       "      <td>0.093957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-2058</th>\n",
       "      <th>1</th>\n",
       "      <td>merkel</td>\n",
       "      <td>0.053148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refugee</td>\n",
       "      <td>0.049351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu</td>\n",
       "      <td>0.038639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3016</th>\n",
       "      <th>1</th>\n",
       "      <td>politic</td>\n",
       "      <td>0.055856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>farron</td>\n",
       "      <td>0.039897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party</td>\n",
       "      <td>0.037484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3665</th>\n",
       "      <th>1</th>\n",
       "      <td>medium</td>\n",
       "      <td>0.081394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate</td>\n",
       "      <td>0.067239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macron</td>\n",
       "      <td>0.053083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            token     value\n",
       "doc               rank                     \n",
       "NewsArticles-119  1           day  0.077434\n",
       "                  2           bbc  0.065935\n",
       "                  3      victoria  0.065935\n",
       "NewsArticles-1206 1           car  0.125276\n",
       "                  2         garda  0.125276\n",
       "                  3     collision  0.093957\n",
       "NewsArticles-2058 1        merkel  0.053148\n",
       "                  2       refugee  0.049351\n",
       "                  3            eu  0.038639\n",
       "NewsArticles-3016 1       politic  0.055856\n",
       "                  2        farron  0.039897\n",
       "                  3         party  0.037484\n",
       "NewsArticles-3665 1        medium  0.081394\n",
       "                  2     candidate  0.067239\n",
       "                  3        macron  0.053083"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_terms_table(tfidf_mat, vocab, labels, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf matrix is calculated from a DTM $D$ as $\\textit{tf}(D) \\cdot \\textit{idf}(D)$.\n",
    "\n",
    "\n",
    "There are different variants for how to calculate the term frequency $\\textit{tf}(D)$ and the inverse document frequency $\\textit{idf(D)}$. The package tmtoolkit contains several functions that implement some of these variants. For $\\text{tf()}$ these are:\n",
    "\n",
    "- [tf_binary](api.rst#tmtoolkit.bow.bow_stats.tf_binary): binary term frequency matrix (matrix contains 1 whenever a term occurred in a document, else 0)\n",
    "- [tf_proportions](api.rst#tmtoolkit.bow.bow_stats.tf_proportions): proportional term frequency matrix (term counts are normalized by document length)\n",
    "- [tf_log](api.rst#tmtoolkit.bow.bow_stats.tf_log): log-normalized term frequency matrix (by default $\\log(1 + D)$)\n",
    "- [tf_double_norm](api.rst#tmtoolkit.bow.bow_stats.tf_double_norm): double-normalized term frequency matrix\n",
    "    $K + (1-K) \\cdot \\frac{D}{\\textit{rowmax}(D)}$, where $\\textit{rowmax}(D)$ is a vector containing the maximum term count per document\n",
    "\n",
    "As you can see, all the term frequency functions are prefixed with a `tf_`. There are also two variants for $\\textit{idf()}$:\n",
    "\n",
    "- [idf](api.rst#tmtoolkit.bow.bow_stats.idf): calculates $\\log(\\frac{a + N}{b + \\textit{df}(D)})$ where $a$ and $b$ are smoothing constants, $N$ is the number of documents and $\\textit{df}(D)$ calculates the [document frequency](#Document-lengths,-document-and-term-frequencies,-token-co-occurrences)\n",
    "- [idf_probabilistic](api.rst#tmtoolkit.bow.bow_stats.idf_probabilistic): calculates $\\log(a + \\frac{N - \\textit{df}(D)}{\\textit{df}(D)})$\n",
    "\n",
    "The term frequency functions always return a sparse matrix if possible and if the input is sparse. Let's try out two term frequency functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.645436Z",
     "iopub.status.busy": "2023-04-05T15:36:32.645264Z",
     "iopub.status.idle": "2023-04-05T15:36:32.648017Z",
     "shell.execute_reply": "2023-04-05T15:36:32.647677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import tf_binary, tf_proportions\n",
    "\n",
    "tf_binary(mat).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.649266Z",
     "iopub.status.busy": "2023-04-05T15:36:32.649168Z",
     "iopub.status.idle": "2023-04-05T15:36:32.651972Z",
     "shell.execute_reply": "2023-04-05T15:36:32.651631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n",
       "        [0.025  , 0.025  , 0.     , ..., 0.     , 0.     , 0.05   ],\n",
       "        [0.     , 0.     , 0.     , ..., 0.     , 0.00606, 0.     ],\n",
       "        [0.     , 0.     , 0.00637, ..., 0.00637, 0.     , 0.     ],\n",
       "        [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_proportions(mat).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the [document frequency](#Document-lengths,-document-and-term-frequencies,-token-co-occurrences) function `doc_frequencies`, the inverse document frequency functions also return a vector with the same length as the vocabulary. Let's use these functions and have a look at the inverse document frequency of certain tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.653259Z",
     "iopub.status.busy": "2023-04-05T15:36:32.653136Z",
     "iopub.status.idle": "2023-04-05T15:36:32.656233Z",
     "shell.execute_reply": "2023-04-05T15:36:32.655910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('110pm', 1.252762968495368),\n",
       " ('70', 1.252762968495368),\n",
       " ('abuse', 1.252762968495368),\n",
       " ('access', 0.9808292530117262),\n",
       " ('accession', 1.252762968495368),\n",
       " ('accusation', 1.252762968495368),\n",
       " ('act', 1.252762968495368),\n",
       " ('addition', 1.252762968495368),\n",
       " ('address', 1.252762968495368),\n",
       " ('administration', 1.252762968495368)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import idf, idf_probabilistic\n",
    "\n",
    "idf_vec = idf(mat)\n",
    "list(zip(vocab, idf_vec))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.657641Z",
     "iopub.status.busy": "2023-04-05T15:36:32.657464Z",
     "iopub.status.idle": "2023-04-05T15:36:32.660473Z",
     "shell.execute_reply": "2023-04-05T15:36:32.660148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('110pm', 1.6094379124341003),\n",
       " ('70', 1.6094379124341003),\n",
       " ('abuse', 1.6094379124341003),\n",
       " ('access', 0.916290731874155),\n",
       " ('accession', 1.6094379124341003),\n",
       " ('accusation', 1.6094379124341003),\n",
       " ('act', 1.6094379124341003),\n",
       " ('addition', 1.6094379124341003),\n",
       " ('address', 1.6094379124341003),\n",
       " ('administration', 1.6094379124341003)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probidf_vec = idf_probabilistic(mat)\n",
    "\n",
    "list(zip(vocab, probidf_vec))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that due to our very small sample, there's not much variation in the inverse document frequency values.\n",
    "\n",
    "By default, [tfidf](api.rst#tmtoolkit.bow.bow_stats.tfidf) uses `tf_proportions` and `idf` to calculate the tf-idf matrix. You can plug in other functions to get other variants of tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.661785Z",
     "iopub.status.busy": "2023-04-05T15:36:32.661664Z",
     "iopub.status.idle": "2023-04-05T15:36:32.664678Z",
     "shell.execute_reply": "2023-04-05T15:36:32.664377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40236, 0.40236, 0.40236, ..., 0.40236, 0.40236, 0.40236],\n",
       "       [0.70413, 0.70413, 0.40236, ..., 0.40236, 0.40236, 1.0059 ],\n",
       "       [0.40236, 0.40236, 0.40236, ..., 0.40236, 0.5748 , 0.40236],\n",
       "       [0.40236, 0.40236, 0.5748 , ..., 0.5748 , 0.40236, 0.40236],\n",
       "       [0.40236, 0.40236, 0.40236, ..., 0.40236, 0.40236, 0.40236]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import tf_double_norm\n",
    "\n",
    "# we also set a \"K\" parameter for \"tf_double_norm\"\n",
    "tfidf_mat2 = tfidf(mat, tf_func=tf_double_norm,\n",
    "                   idf_func=idf_probabilistic, K=0.25)\n",
    "tfidf_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T15:36:32.665995Z",
     "iopub.status.busy": "2023-04-05T15:36:32.665912Z",
     "iopub.status.idle": "2023-04-05T15:36:32.672107Z",
     "shell.execute_reply": "2023-04-05T15:36:32.671758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-119</th>\n",
       "      <th>1</th>\n",
       "      <td>bbc</td>\n",
       "      <td>1.207078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nhs</td>\n",
       "      <td>1.207078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victoria</td>\n",
       "      <td>1.207078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-1206</th>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garda</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collision</td>\n",
       "      <td>1.307668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-2058</th>\n",
       "      <th>1</th>\n",
       "      <td>merkel</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refugee</td>\n",
       "      <td>1.523218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germany</td>\n",
       "      <td>1.092119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3016</th>\n",
       "      <th>1</th>\n",
       "      <td>politic</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>farron</td>\n",
       "      <td>1.264558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putin</td>\n",
       "      <td>1.092119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NewsArticles-3665</th>\n",
       "      <th>1</th>\n",
       "      <td>medium</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate</td>\n",
       "      <td>1.399511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macron</td>\n",
       "      <td>1.189585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            token     value\n",
       "doc               rank                     \n",
       "NewsArticles-119  1           bbc  1.207078\n",
       "                  2           nhs  1.207078\n",
       "                  3      victoria  1.207078\n",
       "NewsArticles-1206 1           car  1.609438\n",
       "                  2         garda  1.609438\n",
       "                  3     collision  1.307668\n",
       "NewsArticles-2058 1        merkel  1.609438\n",
       "                  2       refugee  1.523218\n",
       "                  3       germany  1.092119\n",
       "NewsArticles-3016 1       politic  1.609438\n",
       "                  2        farron  1.264558\n",
       "                  3         putin  1.092119\n",
       "NewsArticles-3665 1        medium  1.609438\n",
       "                  2     candidate  1.399511\n",
       "                  3        macron  1.189585"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_terms_table(tfidf_mat2, vocab, labels, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Once we have generated a DTM, we can use it for topic modeling. The [next chapter](topic_modeling.ipynb) will show how tmtoolkit can be used to evaluate the quality of your model, export essential information from it and visualize the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
